```python
# Initialize Otter
import otter
grader = otter.Notebook("lab3.ipynb")
```

<img src="img/dsci511_header.png" width="600">

# Lab 3: Introduction to NumPy and Control flow

## Instructions

rubric={mechanics:5}

Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).

Check off that you have read and followed each of these instructions:

- [X] All files necessary to run your work must be pushed to your GitHub.ubc.ca repository for this lab.
- [X] You need to have a minimum of 3 commit messages associated with your GitHub.ubc.ca repository for this lab.
- [X] You must also submit `.ipynb` file and the rendered PDF in this worksheet/lab to Gradescope. Entire notebook must be executed so the TA's can see the results of your work. 
- [X] **There is autograding in this lab, so please do not move or rename this file. Also, do not copy and paste cells, if you need to add new cells, create new cells via the "Insert a cell below" button instead.**
- [X] To ensure you do not break the autograder remove all code for installing packages (i.e., DO NOT have `! conda install ...` or `! pip install ...` in your homework!
- [X] Follow the [MDS general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).
- [X] <mark>This lab has hidden tests. In this lab, the visible tests are just there to ensure you create an object with the correct name. The remaining tests are hidden intentionally. This is so you get practice deciding when you have written the correct code and created the correct data object. This is a necessary skill for data scientists, and if we were to provide robust visible tests for all questions you would not develop this skill, or at least not to its full potential.</mark>

## Code Quality
rubric={quality:5}

The code that you write for this assignment will be given one overall grade for code quality, see [MDS code quality rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_quality.md) as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the PEP 8 code style. There is a guide you can refer too: https://peps.python.org/pep-0008/

Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?).

## Writing 
rubric={writing:5}

To get the marks for this writing component, you should:

- Use proper English, spelling, and grammar throughout your submission (the non-coding parts).
- Be succinct. This means being specific about what you want to communicate, without being superfluous.



```python
import time
import numpy as np
import pandas as pd
import math
from random import gauss
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ['png']
plt.rcParams.update({'font.size': 14, 'axes.labelweight': 'bold'})
```

## Exercise 1: NumPy wrangling

### 1.1: Flip the image
rubric={autograde:10}

Below is a 400 x 400 pixel image of the UBC logo, imported and displayed with `matplotlib` (one of the most popular Python plotting packages).


```python
image = plt.imread('img/ubc.jpeg')[:, :, 0]
plt.imshow(image, cmap='gray')

print(f"Image shape: {image.shape}")
print(f"Max. pixel value: {image.max()}")
print(f"Min. pixel value: {image.min()}")
```

    Image shape: (400, 400)
    Max. pixel value: 255
    Min. pixel value: 0



    
![png](./lab3_10_1.png)
    


**Note:** The `cmap=gray` parameter in `plt.imshow()` is to force `matplotlib` to interpret the array as grayscale values (instead of showing an irrelevant colormap by default).

As you can see, `image` is just a NumPy array of size `(400, 400)`, with values ranging from 0 to 255.

Your task is to write a code that **flips the image about both the horizontal and vertical axes**, so that it looks as if we rotated the image 180 degrees clockwise:

![](img/ubc_flipped.jpeg)

- Do not overwrite the `image` variable, we will use it in later questions.

- NumPy has helpful functions for "flipping" arrays. Be sure to read the `numpy.flip()` docs ([here](https://numpy.org/doc/stable/reference/generated/numpy.flip.html)) to see how it works.
- Save your answer in a variable named `result`.

- **Don't forget to show your resulting image in the output using `plt.imshow()`.**


```python
# Save your answer as result
result = np.fliplr(np.flipud(image))

# Display the flipped image
plt.imshow(result, cmap='gray')
plt.show()
```


    
![png](./lab3_12_0.png)
    



```python
grader.check("q1_1")
```




<p><strong><pre style='display: inline;'>q1_1</pre></strong> passed! ðŸš€</p>



### 1.2: Add a black border
rubric={autograde:10}

Suppose that you want to prepare this image to post on Instagram, and you think a 20-pixels-wide black border will really make it stand out. Add a 20-pixels-wide black border to the image so that it looks like this:

![](img/ubc_border.jpeg)

**Hints:**

- The image including the border should remain 400 x 400 pixels (i.e., you are adding the border within the image), **do not** add it to the outside and make the image 440 x 440 pixels.

- Black pixels have a value of `0` (i.e., they have 0 brightness).

- There are many ways to solve this question so do it however you like, but `np.pad()` might be super helpful to make your solution shorter.
- Save your answer in a variable named `padded`.

- **Don't forget to show your resulting image in the output using `plt.imshow()`.**


```python
n = 20  # border size

# Save your answer as padded
padded = np.pad(image[20:380, 20:380], pad_width=n,
                mode='constant', constant_values=0)

plt.imshow(padded, cmap='gray')
```




    <matplotlib.image.AxesImage at 0x7f3f437ac080>




    
![png](./lab3_16_1.png)
    



```python
grader.check("q1_2")
```




<p><strong><pre style='display: inline;'>q1_2</pre></strong> passed! ðŸŽ‰</p>



## Exercise 2: Control Flow and List Comprehensions 

### 2.1: Reading a file and calculating the average AQI index
rubric={accuracy:5,reasoning:5}

Your first task is to read data from a text file (.txt) and compute a few quantities using loops and `if..else` conditions. 

There was a major (> 8,600 acres) wildfire (named the El Dorado fire) that started on Saturday, September 5, 2020 in San Bernardino County which blame has been assigned to the use of a smoke-generating pyrotechnic device at a gender reveal party (Source: https://www.cbc.ca/news/world/califoronia-wildfires-september-7-gender-reveal-party-1.5714719). 

> <img src="https://i.cbc.ca/1.5715027.1599506927!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/california-wildfires.jpg" width=300>
>
> *A firefighter battles the Creek Fire as it threatens homes in the Cascadel Woods neighborhood of Madera County, Calif., on Monday, Sept. 7, 2020. (Noah Berger/The Associated Press)*
Below we give you two ordered lists, the first contains the air quality index (AQI) values, the daily reported measured values of AQI, for the area of Los Angeles-Long Beach-Anaheim, California, USA for 18 days. This is the closest major city to the El Dorado fire. The second ordered list contains the dates for each measurement. 
> 
> Data source: https://www.epa.gov/outdoor-air-quality-data/air-data-daily-air-quality-tracker

<!-- Your task is to use base R control flow (specifically `for` loops and `if`/`else` statements) to calculate the average of the maximum daily AQI measurements, before the fire began, and afterwards. Use a `print` statement to output your results in a sentence that communicates your findings. *Hint: `paste` will be a useful function for this.*  -->



There are three tasks for you:
1. Open the `la_aqi_data.txt` using `np.loadtxt()` function with  `dtype=str` and `delimiter=","` arguments.
2. Use Python `for` loops and `if`/`else` statements to calculate the average of the maximum daily AQI measurements, both before the fire began and afterwards. 
3. Use `print` statement(s) to output your results in one or two sentences that communicate your findings. Do not hard-code the values in the `print` statements. You must use the pre-defined variables like 
`avg_max_before`, 
`before_count`,
`avg_max_after`, and 
`after_coun` inside your `print` statement(s) to report the numbers.

> Note: treat the AQI from `2020-09-05` (the day the fire started) in the group after the fire.




```python

# Initialize variables
avg_max_before = 0
before_count = 0
avg_max_after = 0
after_count = 0


# Read data
aqi_data = np.loadtxt('la_aqi_data.txt', dtype=str, delimiter=",")
dates = aqi_data[:, 0]
aqi_values = aqi_data[:, 1].astype(int)

# Open the la_aqi_data.txt file using np.loadtxt() function with  dtype=str and delimiter=","
# Hint: you might want to store the dates and aqi values in two np arrays.
# Hint: do not forget to convert the aqi values to integet using .astype(int)

for i in range(len(aqi_values)):
    if dates[i] < '2020-09-05':
        avg_max_before += aqi_values[i]
        before_count += 1
    else:
        avg_max_after += aqi_values[i]
        after_count += 1
```


```python
# Print your results here
print(
    f"The average max AQI before Sep 5, 2020 was {avg_max_before / before_count:.2f} while the average max AQI after Sep 5, 2020 was {avg_max_after / after_count:.2f}")
```

    The average max AQI before Sep 5, 2020 was 62.22 while the average max AQI after Sep 5, 2020 was 134.89


### 2.2: List comprehensions

rubric={accuracy:5,reasoning:5}


Imagine you are working as a data analyst for a popular movie streaming platform. The platform has gathered data on user ratings for various movies. The ratings are stored in a list of tuples, where each tuple contains the movie title and its user rating (on a scale from 1 to 10). 

Your task is to filter out movies that have a rating of 7 or higher, as the company considers these â€œhighly ratedâ€ and wants to recommend them to other users.

1. Write a Python script that takes in a list of movie ratings (as described) and uses list comprehension to create a new list containing only the titles of movies with a rating of 7 or higher.
2. Save the list under the variable `highly_rated_movies` and print its contents. 

<!-- BEGIN QUESTION -->




```python
# Define the list of movies with their ratings
movies = [
    ("The Matrix", 8),
    ("Inception", 9),
    ("The Room", 3),
    ("Toy Story", 7),
    ("Cats", 4)
]

highly_rated_movies = []

for movie, rating in movies:
    if rating >= 7:
        highly_rated_movies.append(movie)
```


```python
# Print the result
print(highly_rated_movies)
```

    ['The Matrix', 'Inception', 'Toy Story']


<!-- END QUESTION -->

## Exercise 3: Pairwise Distance Matrix - Loops vs. Vectorization 

In many applications (machine learning, physics, computational geometry), we often need to compute distances between points in space. For example, in clustering, we compare distances between data points.

This exercise explores how to compute pairwise distances efficiently using NumPy vectorization instead of nested Python loops.
The picture below is to help you visualize pairwise distance calculation. Note that the figure shows the distances only for one point.

<img src="img/q2.jpeg" width="600" align=middle>

You are given `n` points in 2D space. The points are represented as two arrays:

- $X$ of shape `(n,)` for x-coordinates
- $Y$ of shape `(n,)` for y-coordinates

We want to compute the pairwise distance matrix $D$ where $D[i,j]$ (the entry in row $i$ and column $j$) is the Euclidean distance between point $i$ and point $j$.


### 3.1: Compute pairwise distance matrix with Python loop
rubric={autograde:10}

Your task in this question is to write a **nested loop** to compute the pairwise distance matrix $D$, such that

$$ D[i,j] = \sqrt{(X[i] - X[j])^2 + (Y[i] - Y[j])^2} $$

Save your result under the variable `D_loop`.


```python
# Let's start it with 5 points
# X and Y contain the coordinates of the five points 

X = np.array([0, 3, 4, 7, 1])
Y = np.array([0, 4, 3, 1, 6])

n = len(X)
# Lets call the pairwise distance matrix D_loop
D_loop = np.zeros((n, n))
for i in range(n):
    for j in range(n):
                D_loop[i, j] = math.sqrt((X[i] - X[j])**2 + (Y[i] - Y[j])**2)

D_loop       
```




    array([[0.        , 5.        , 5.        , 7.07106781, 6.08276253],
           [5.        , 0.        , 1.41421356, 5.        , 2.82842712],
           [5.        , 1.41421356, 0.        , 3.60555128, 4.24264069],
           [7.07106781, 5.        , 3.60555128, 0.        , 7.81024968],
           [6.08276253, 2.82842712, 4.24264069, 7.81024968, 0.        ]])




```python
grader.check("q3_1")
```




<p><strong><pre style='display: inline;'>q3_1</pre></strong> passed! ðŸ’¯</p>



### 3.2: Compute pairwise distance matrix with NumPy vectorization
rubric={accuracy:5,reasoning:5}

In this question, your task is to rewrite the above computation in vectorized code. Carry out the following: 

1. Rewrite the computation using NumPy broadcasting and vectorization.
2. Save your result under the variable `D_vec`.
3. Confirm that both versions produce the same result.

> Hint: First construct matrices `dx_vec` and `dy_vec` that have the same shape as the desired `D_vec` but contain only the differences in `x` and `y` coordinates respectively. Make use of [NumPy broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) to automatically create matrices of the correct shape.

<!-- BEGIN QUESTION -->




```python
# Lets call the pairwise distance matrix D_vec
D_vec = None

X = np.array([0, 3, 4, 7, 1])
Y = np.array([0, 4, 3, 1, 6])

dx_vec = np.zeros((n, n)) + X
dx_vec = np.abs(dx_vec - dx_vec.T)

dy_vec = np.zeros((n, n)) + Y
dy_vec = np.abs(dy_vec - dy_vec.T)

D_vec = np.sqrt(dx_vec**2 + dy_vec**2)

D_vec
```




    array([[0.        , 5.        , 5.        , 7.07106781, 6.08276253],
           [5.        , 0.        , 1.41421356, 5.        , 2.82842712],
           [5.        , 1.41421356, 0.        , 3.60555128, 4.24264069],
           [7.07106781, 5.        , 3.60555128, 0.        , 7.81024968],
           [6.08276253, 2.82842712, 4.24264069, 7.81024968, 0.        ]])




```python
# Compare the two pairwise distance matrices
print("Same result?", np.allclose(D_loop, D_vec))
```

    Same result? True



```python
# Let's visualize the pairwise distance matrix as a heat map

plt.figure(figsize=(6, 5))
plt.imshow(D_vec, cmap="viridis", origin="lower")
plt.colorbar(label="Distance")
plt.title("Pairwise Distance Matrix Heatmap")
plt.xlabel("Point index (X)")
plt.ylabel("Point index (Y)")
plt.show()
```


    
![png](./lab3_40_0.png)
    


<!-- END QUESTION -->

### 3.3: Performance Comparision
rubric={accuracy:5,reasoning:5}

<!-- BEGIN QUESTION -->


The goal of this question is to help drive home the power of vectorized array operations in NumPy vs iteration in base Python.

Your task is to write code to record how long it takes to run the loop implementation and the vectorized implementation.
You can use the `time` module to help calculate the time it takes (in [real time](https://communities.sas.com/t5/SAS-Programming/Real-Time-vs-CPU-time/td-p/287743#:~:text=Real%20Time%20is%20the%20actual,the%20step%20utilises%20CPU%20resources.)) for your code to execute.

For testing, we will define large $X_{\mathrm{rand}}$ and $Y_{\mathrm{rand}}$ arrays with `n` elements for different values of `n`. 

1. Compute pairwise distances for large arrays `X_rand` and `Y_rand` with both iterated loops and vectorization, where: `n = 100`, `n = 1_000`, `n = 10_000`.
2. Record the time taken in each case and report it with the help of a `print` statement.
3. Do you see a speed-up when using the vectorized implementation? If yes, why? Write 1â€“2 sentences to summarize your reflection.


The `time` module can be used to get the current clock time. Save a variable `start = time.time()` before the code you wish to test and `end = time.time()` after. Comparing the difference (`end - start`) provides the length of time required to execute the code within the block. Here is an example:
```python
import time
start = time.time()
# code block here
end = time.time()
print("Elapsed time:", end - start, "seconds")
```


**Note:**

- The `time` module has already been imported for you at the start of the lab.





## For loops:
Elapsed time: 0.009566545486450195 seconds

Elapsed time: 0.7304041385650635 seconds

Elapsed time: 73.5680742263794 seconds

## Vectorization and broadcasting:

Elapsed time: 0.0006275177001953125 seconds

Elapsed time: 0.017798185348510742 seconds

Elapsed time: 1.563312292098999 seconds


## Explanation: 
Much faster with the vectorized implementation since Numpy is coded in C and is much more memory efficient than Python is at the same task.


```python
import time
# Lets define large X_rand and Y_rand arrays to do the performance comparison.
# We will use three values, n = 100, 1000, 10_000
temp_loop = []
for n in [100, 1000, 10_000]:
    X_rand = np.random.rand(n)
    Y_rand = np.random.rand(n)

    # Write your solution below
    start = time.time()
    # for i in range(n):
    #     for j in range(n):
    #             math.sqrt((X_rand[i] - X_rand[j])**2 + (Y_rand[i] - Y_rand[j])**2)
    dx_vec = np.zeros((n, n)) + X_rand
    dx_vec = np.abs(dx_vec - dx_vec.T)

    dy_vec = np.zeros((n, n)) + Y_rand
    dy_vec = np.abs(dy_vec - dy_vec.T)

    D_vec = np.sqrt(dx_vec**2 + dy_vec**2)

    end = time.time()
    print("Elapsed time:", end - start, "seconds")
```

    Elapsed time: 0.0009837150573730469 seconds
    Elapsed time: 0.01712942123413086 seconds
    Elapsed time: 1.572106122970581 seconds


<!-- END QUESTION -->

## Exercise 4: Convolution Neural Network mean pulling (CHALLENGING)
rubric={accuracy: 5}

In DSCI 572 you'll learn about [Convolutional Neural Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN), which are often used when working with image data. A common operation in a CNN architecture is [pooling](https://cs231n.github.io/convolutional-networks/#pool), in which you reduce the size of an image by looking at a small window of pixels, say a 4 x 4 window of pixels, and representing that window using e.g., the max/min/mean value of the pixels in the window.

Below is an example of mean pooling, transforming a 6 x 6 image into a 3 x 3 image by taking the mean of 2 x 2 pixel windows:

<img src="https://stanford.edu/~shervine/teaching/cs-230/illustrations/average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f" width="400">

Source: [stanford.edu](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)

Let's implement pooling in NumPy here to get a feel of how it works. We can do it by reshaping our image into `n x n` windows and then calculating the `.max()` of each window. Your task here is to implement **mean** pooling on the UBC logo image using a `10 x 10` window, resulting in an image that will look like this:

![](img/ubc_mean_pool.jpeg)

**Hints:**

- There are plenty of ways you could solve this question. One way is to start by reshaping each axis of the image into shape `(40, 10)` to end up with a 4D array of shape `(40, 10, 40, 10)`.

- Then apply `.mean()` to the reshaped data on both axes of size 10. You can specify multiple axes to operate on simultaneously by passing a tuple to the `axis=` parameter of the `mean()` method.

- Play around with you code to get a feel for what pooling does. What happens if you increase/decrease the pooling window size? Also feel free to try using `min()` or `max()` methods, for example: 

![](img/ubc_min_pool.jpeg)

- See [here](https://stackoverflow.com/a/42463514) for more help.

- **Don't forget to show your resulting image in the output using `plt.imshow()`**

_Type your answer here, replacing this text._

<!-- BEGIN QUESTION -->




```python
...
```




    Ellipsis



<!-- END QUESTION -->


