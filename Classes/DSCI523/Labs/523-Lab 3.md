---

title: "DSCI 523 Lab 3"

subtitle: "Tidy control flow in R, as well as functions & testing in R"

output: html_document

---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

## Lab Mechanics

rubric={mechanics:5}

- All files necessary to run your work must be pushed to your GitHub.ubc.ca repository for this lab.

- You need to have a minimum of 3 commit messages associated with your GitHub.ubc.ca repository for this lab.

- You must also submit `.Rmd` file and the rendered pdf in this worksheet/lab to Gradescope. Entire notebook must be executed so the TA's can see the results of your work. 

- **There is autograding in this lab, so please do not move or rename this file. Also, do not copy and paste cells, if you need to add new cells, create new cells via the "Insert a cell below" button instead.**

- To ensure you do not break the autograder remove all code for installing packages (i.e., DO NOT have `install.packages(...)` or `devtools::install_github(...)` in your homework!

- Follow the [MDS general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).

- <mark>This lab has hidden tests. In this lab, the visible tests are just there to ensure you create an object with the correct name. The remaining tests are hidden intentionally. This is so you get practice deciding when you have written the correct code and created the correct data object. This is a necessary skill for data scientists, and if we were to provide robust visible tests for all questions you would not develop this skill, or at least not to its full potential.</mark>

## Code Quality

rubric={quality:5}

The code that you write for this assignment will be given one overall grade for code quality, see our code quality rubric as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the tidyverse code style. There is a guide you can refer too: http://style.tidyverse.org/

Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?).

## Writing 

rubric={writing:5}

To get the marks for this writing component, you should:

- Use proper English, spelling, and grammar throughout your submission (the non-coding parts).

- Be succinct. This means being specific about what you want to communicate, without being superfluous.

## Let's get started!

Run the cell below to load the libraries needed for this lab, as well as the test file so you can check your answers as you go!

```{r}

library(nycflights13)

library(janitor)

library(testthat)

library(readr)

library(dplyr)

library(purrr)

library(tidyr)

library(ggplot2)

```

> Note - there is an issue with loading packages with `tidyverse` and the autograding software we are using.

Thus, for assignments, please load the packages individually as I have done above instead of loading them via the tidyverse.

## Exercise 1: control flow with {dplyr}

rubric={autograde=15}

Use the {tidyverse} control flow functions we learned about this week to take the {nycflights13} `flights` data set and obtain the average speed (in km/hr) and average distance (in km) for the carriers AA, AS, UA and US.

Name these new columns `avg_speed` and `avg_distance_km`, and round the values so that the answer is a whole number (i.e., no decimal points). Convert the carrier acronyms to their full names (American Airlines, Alaska Airlines, 

United Airlines and US Airways). Sort the results according to the average speed. Bind the name `avg_flights` to the data frame.

Some hints:

- The distance is in miles and air time is in minutes in the `flights` data. 

- You will have to create a column that holds the average speed for each flight before you can do this for each carrier.

- You may also need to handle `NA` entries in the data.

```{r}

avg_flights <- flights %>%

  filter(carrier == c("AA", "AS", "UA", "US")) %>%

  mutate(carrier = case_when(

    carrier == "AA" ~ "American Airlines",

    carrier == "AS" ~ "Alaska Airlines",

    carrier == "UA" ~ "United Airlines",

    carrier == "US" ~ "US Airways"

  )) %>%

  mutate(distance = distance * 1.60934) %>%

  mutate(avg_speed = distance / (air_time / 60)) %>%

  group_by(carrier) %>%

  summarise(

    avg_speed = round(mean(avg_speed, na.rm = TRUE), 0),

    avg_distance_km = round(mean(distance, na.rm = TRUE), 0)

  ) %>%

  arrange(desc(avg_speed))

avg_flights

```

The tests below only check that the object has the correct names. The other tests are intentionally hidden.

```{r}

. <- ottr::check("tests/e1.R")

```

## Exercise 2: mapping with {purrr}

rubric={accuracy:20}

We want to know if the list mixed_bag given below contains all numeric elements, if it does, we want to output `TRUE`. If not, we want to output `FALSE`.

To do this use a {purrr} `map*` function to iterate over the list given below to generate a logical vector that holds `TRUE` if the list element is numeric and `FALSE` if it is not. Then use the fact that R can sum logical vectors (`TRUE` takes on the value of 1 and `FALSE` takes on the value of 0) and check whether the sum of the logical vector generated by map equals the length of the mixed_bag list.

```{r}

mixed_bag <- list(

  c(11232, 21231, 32123),

  "https://github.com/UBC-DSCI/introduction-to-datascience",

  c(TRUE, FALSE, FALSE, TRUE, TRUE),

  c("CRC Press"),

  list(1, 2, 3)

)

mixed_bag %>%

  map_lgl(is.numeric) %>%

  sum() == length(mixed_bag)

```

## Exercise 3: functions

rubric={accuracy:10, reasoning:6}

#### Part 1: 

Consider the code below, 

where we are repeatedly reading in data from Vancouver's Open Data portal,

and cleaning the column names (so that no column names are non-syntactic). 

Your job is to take the redundant code and make it modular,

by wrapping it in a function.

Your function should meet the following specifications:

- input: a URL to a `.csv` from Vancouver's Open Data portal

- output: a tibble with syntactic column names

> If you feel inspired, feel free to make your function more flexible 

> by using function arguments!

Your function should follow the tidyverse style guide, 

as well as be well documented using `roxygen2` documentation.

Finally, demonstrate that your function works using an example.

#### Part 2:

In 2-3 sentences, and in your own words, 

also discuss why it would be worth modularizing the code into a function 

if you were not repeating it several times 

(i.e., you were just using it to read in the data once).

```{r}

# code to modularize

washrooms <- read_delim("https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/public-washrooms/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B",

  delim = ";"

)

parks <- read_delim("https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/parks/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B",

  delim = ";"

)

art <- art_data <- read_delim("https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/public-art/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B",

  delim = ";"

)

clean_washrooms <- washrooms |>

  clean_names()

clean_parks <- parks |>

  clean_names()

clean_art <- art |>

  clean_names()

```

Modularizing code is useful since we can write unit tests to make sure our function works as expected. Designing our own function can help with debugging since it is easier to isolate bugs

```{r}

clean_data <- function(url) {

  #' Clean Vancouver Open Data

  #'

  #' This function reads in a CSV file from Vancouver's Open Data portal

  #' and cleans the column names to be syntactic.

  #'

  #' @param url A string representing the URL to a CSV file from Vancouver's Open Data portal.

  #' @return A tibble with syntactic column names.

  #' @examples

  #' clean_data("https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/public-washrooms/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B")

  data <- read_delim(url, delim = ";")

  clean_data <- clean_names(data)

  return(clean_data)

}

clean_washrooms_func <- clean_data("https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/public-washrooms/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B")

test_that("clean_data function works", {

  expect_equal(colnames(clean_washrooms_func), colnames(clean_washrooms))

})

```

## Exercise 4: testing

rubric={accuracy:18} 

Sample variance of data generated from a normal/Gaussian distribution is defined as:

$variance = \frac{\Sigma{(x-mean)^2}}{n-1}$

where $mean$ is the mean of our observations, $x$ is each individual observation, and $n$ is the number of observations.

Your task is to use test driven development to write a function that calculates the variance from scratch (*i.e.*, do not use the `var` function in R). Your function should take in a vector, and return a vector of length 1. Make sure you use defensive programming so that your function will fail early (and provides useful error messages) if the user provides incorrect inputs (e.g., lists, data frames, etc). Use {testthat} statements to check the correctness of your function on tractable edge cases, as well as to check that your function handles exceptions as expected. 

*Hint - you likely need to avoid using {tidyverse} functions in your solution as we will not learn how to write functions with them until next week (they are a little trickier to program with due to their unquoted column names).*

```{r}

calculate_variance <- function(x) {

  mean <- 0

  n <- 0

  sum_square <- 0

  var <- 0

  if (!is.numeric(x) | !is.vector(x)) {

    return(NA)

  } else if (is.vector(x) & length(x) == 1) {

    return(NA)

  } else {

    mean <- mean(x)

    n <- length(x)

    for (i in seq_along(x)) {

      sum_square <- sum_square + (x[i] - mean)^2

    }

    var <- sum_square / (n - 1)

  }

  var

}

not_vec <- data.frame("Abc" = c(1, 2, 3))

len_1_vec <- c(32)

normal_vec <- c(10, 5, 3)

same_vec <- c(5, 5, 5, 5, 5, 5, 5, 5)

test_that("Input accepts vectors of length 2 or more only", {

  expect_true(is.na(calculate_variance(not_vec)))

  expect_true(is.na(calculate_variance(len_1_vec)))

  expect_false(is.na(calculate_variance(normal_vec)))

})

test_that("Variance is computed correctly", {

  expect_equal(calculate_variance(normal_vec), var(normal_vec))

  expect_equal(calculate_variance(same_vec), 0)

})

```

## Exercise 5: (Challenging)

rubric={accuracy:5}

**Warning: This exercise is challenging and could be time-consuming. Please only attempt if you find yourself finishing the assignment early and you want a bit more of a challenge.**

We're going to be working with a data set from Kaggle to further explore the {purrr} `map*` functions. This data was collected under the instructions from Madrid's City Council and is publicly available on their website. It is named `madrid_pollution.tsv` and is available here https://github.com/UBC-DSCI/dsci-100-assets/blob/master/2019-fall/materials/worksheet_03/data/madrid_pollution.csv?raw=true. This data includes daily and hourly measurements of air quality from 2001 to 2006. Pollutants are categorized based on their chemical properties. More information about this data set can be found [here](https://www.kaggle.com/decide-soluciones/air-quality-madrid). 

In this exercise we want you to use create a subset of this data frame called that contains only the records for the year 2006, and only the columns with the pollutant values. Then we want you to use a {purrr} `map*` function and a standard error function (that you write yourself) to obtain the standard errors for each pollutant in 2006 stored as a tibble. 

The standard error of a normal distribution is defined as the standard deviation divided by the square root of the number of observations:

$$se = \frac{sd}{\sqrt{n}}$$

There is no function for this in R, so for this question you need to write this yourself. Be sure to also write tests for your function to prove that it works as expected.

```{r}

```

> Note - there is a new {tidyverse} function, `across`, that is also useful for applying a function across columns (docs: https://dplyr.tidyverse.org/reference/across.html), however we focus on teaching `map_*` in MDS as it is more general. Feel free to use either in future if the use of `map_*` is not specified.

## Exercise 6: (Optional)

rubric={accuracy:0}

Ask a large language model (LLM) to complete exercise 4 for you 

(note - in exercise 4 you are expected to first answer it on your own, 

without a the help of an LLM). 

Share here your prompts and the solutions. 

Did you see any improvements to your solution? 

Did it make any mistakes?

_Type your answer here, replacing this text._

Congratulations! You are done the lab!!! Pat yourself on the back, and submit your lab to **GitHub** and Gradescope! Make sure you have 3 Git commits!